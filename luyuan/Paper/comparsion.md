## 对比RCNN, Fast-RCNN, Faster-RCNN
created by Lu Yuan, August 30th, 2019

## 步骤对比
#### RCNN
1. 在图像中确定约1000-2000个候选框 (使用选择性搜索)
2. 每个候选框内图像块缩放至相同大小，并输入到CNN内进行特征提取 
3. 对候选框中提取出的特征，使用分类器判别是否属于一个特定类
4. 对于属于某一特征的候选框，用回归器进一步调整其位置

#### Fast RCNN
1. 在图像中确定约1000-2000个候选框 (使用选择性搜索)
2. 对整张图片输进CNN，得到feature map
3. 找到每个候选框在feature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层
4. 对候选框中提取出的特征，使用分类器判别是否属于一个特定类
5. 对于属于某一特征的候选框，用回归器进一步调整其位置

#### Faster RCNN
1. 对整张图片输进CNN，得到feature map
2. 卷积特征输入到RPN，得到候选框的特征信息
3. 对候选框中提取出的特征，使用分类器判别是否属于一个特定类
4. 对于属于某一特征的候选框，用回归器进一步调整其位置

## 对比RCNN和Fast-RCNN
RCNN的缺点是由于每一个候选框都要独自经过CNN，这使得花费的时间非常多。解决方法是共享卷积层，现在不是每一个候选框都当做输入进入CNN了，而是输入一张完整的图片，在第五个卷积层再得到每个候选框的特征。 Fast RCNN相对于RCNN的提速原因就在于，Fast-RCNN不像RCNN把每个候选区域给深度网络提特征，而是整张图提一次特征，再把候选框映射到conv5上，而SPP只需要计算一次特征，剩下的只需要在conv5层上操作就可以了。
#### 原来的方法
许多候选框（比如两千个）-->CNN-->得到每个候选框的特征-->分类+回归
#### 现在的方法
一张完整图片-->CNN-->得到每张候选框的特征-->分类+回归

## SPP Net
1. 结合空间金字塔方法实现CNNs的对尺度输入
2. 只对原图提取一次卷积特征:在R-CNN中，每个候选框先resize到统一大小，然后分别作为CNN的输入，这样是很低效的。SPP Net根据这个缺点做了优化,只对原图进行一次卷积得到整张图的feature map，然后找到每个候选框zaifeature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层，节省了大量的计算时间。

## 对比Fast-RCNN和Faster-RCNN
R-CNN的进阶版Fast R-CNN就是在RCNN的基础上采纳了SPP Net方法，对RCNN作了改进，使得性能进一步提高。Fast R-CNN存在的问题是存在瓶颈，使用选择性搜索，找出所有的候选框，这个也非常耗时。解决的方法是加入一个提取边缘的神经网络，也就说找到候选框的工作也交给神经网络来做了